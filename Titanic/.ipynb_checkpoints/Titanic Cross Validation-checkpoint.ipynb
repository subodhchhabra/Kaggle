{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "from time import time\n",
    "from IPython.core.display import Image\n",
    "\n",
    "# Scikit-learn:\n",
    "# # Model:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # PCA:\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "\n",
    "# # Metrics:\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:197: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Vindico/Projects/Data/Kaggle/Competition/Titanic/train.csv')\n",
    "\n",
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "df['Age'] = df['Age'].fillna(age_mean)\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "mode_embarked = mode(df['Embarked'])[0][0]\n",
    "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = df.values[:]\n",
    "\n",
    "X = train_data[:, 2:]\n",
    "y = train_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cv(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=10,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    \n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def accuracy(y_true,y_pred):\n",
    "    # NumPy interprets True and False as 1. and 0.\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector machines:\n",
      "0.709\n",
      "Logistic Regression:\n",
      "0.797\n",
      "Gradient Boosting Classifier:\n",
      "0.825\n",
      "Bagging Classifier:\n",
      "0.802\n",
      "Extra Trees Classifier:\n",
      "0.797\n",
      "Decision Tree Classifier:\n",
      "0.782\n",
      "K-Neighbors Classifier:\n",
      "0.701\n",
      "Random Forest Classifier:\n",
      "0.811\n",
      "AdaBoost Classifier:\n",
      "0.811\n"
     ]
    }
   ],
   "source": [
    "print \"Support vector machines:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,SVC))\n",
    "\n",
    "print \"Logistic Regression:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,LogisticRegression))\n",
    "\n",
    "print \"Gradient Boosting Classifier:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,GradientBoostingClassifier))\n",
    "\n",
    "print \"Bagging Classifier:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,BaggingClassifier))\n",
    "\n",
    "print \"Extra Trees Classifier:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,ExtraTreesClassifier))\n",
    "\n",
    "print \"Decision Tree Classifier:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,DecisionTreeClassifier))\n",
    "\n",
    "print \"K-Neighbors Classifier:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,KNeighborsClassifier))\n",
    "\n",
    "print \"Random Forest Classifier:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,RandomForestClassifier))\n",
    "\n",
    "print \"AdaBoost Classifier:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,AdaBoostClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.788888888889\n",
      "prediction accuracy: 0.808988764045\n",
      "prediction accuracy: 0.797752808989\n",
      "prediction accuracy: 0.831460674157\n",
      "prediction accuracy: 0.85393258427\n",
      "prediction accuracy: 0.831460674157\n",
      "prediction accuracy: 0.820224719101\n",
      "prediction accuracy: 0.775280898876\n",
      "prediction accuracy: 0.887640449438\n",
      "prediction accuracy: 0.865168539326\n",
      "0.865168539326\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n=len(train_data), n_folds=10)\n",
    "\n",
    "for training_set, test_set in cv:\n",
    "    X_train = X[training_set]\n",
    "    y_train = y[training_set]\n",
    "    X_test = X[test_set]\n",
    "    y_test = y[test_set]\n",
    "    model = GradientBoostingClassifier(min_samples_split=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prediction = model.predict(X_test)\n",
    "    print \"prediction accuracy:\", np.sum(y_test == y_prediction)*1./len(y_test)\n",
    "print np.mean(y_test == y_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
